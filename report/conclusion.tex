\documentclass[bare_jrnl_transmag]{subfiles}
\begin{document}

This report covered the development of a state estimation system for drone pose and position using measurements from an IMU and a camera. The overall state estimator was based on a Kalman filter. The predict step employed a Madgwick filter to obtain a filtered orientation of the drone, which was then used to rotate the IMU acceleration data into the world frame. The camera sensors were used to perform visual-inertial odometry and to estimate the drone's position. The camera's position estimate served as the measurement for updating the Kalman filter. The Kalman filter was tuned using process and measurement noise covariance matrices, which were iteratively refined to achieve the best fit. The final RMSE of the Kalman filter was [5.02, 3.17, 4.30] for the x, y, and z axes respectively, when tested on a validation dataset.

Further recommendations to improve the overall VIO and Kalman filter performance include investigating position drift in the VIO, which causes the overall state estimate to diverge over time. Another major improvement would involve using profiling tools to identify bottlenecks in the code and algorithm. This would help optimize performance and enable more reliable real-time operation. Such improvements are important for deployment on a drone, where low-latency and real-time performance are critical.

\end{document}